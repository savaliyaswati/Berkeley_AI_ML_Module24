{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Predicting Housing Prices\n",
    "### Berkeley AI/ML Professional Certificate\n",
    "---\n",
    "This notebook explores housing price prediction using regression and tree-based models. The goal is to understand which factors drive home prices and how well machine learning can predict them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset (Kaggle Ames Housing dataset)\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/AmesHousing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "df.info()\n",
    "df.describe().T.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "missing[missing > 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of SalePrice\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['SalePrice'], kde=True)\n",
    "plt.title('Distribution of Home Sale Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with SalePrice\n",
    "corr = df.corr(numeric_only=True)['SalePrice'].sort_values(ascending=False)\n",
    "corr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of top correlated features\n",
    "top_corr_features = corr.index[1:11]\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[top_corr_features].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Top Correlated Features with SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "df = df.dropna(axis=1, thresh=len(df)*0.7)\n",
    "\n",
    "# Simple fill for remaining missing values\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('SalePrice', axis=1)\n",
    "y = df_encoded['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.001),\n",
    "    'DecisionTree': DecisionTreeRegressor(max_depth=5),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [5, 10, None]}\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_preds = best_model.predict(X_test)\n",
    "best_rmse = np.sqrt(mean_squared_error(y_test, best_preds))\n",
    "best_r2 = r2_score(y_test, best_preds)\n",
    "\n",
    "best_rmse, best_r2, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Findings and Interpretation\n",
    "### Key Insights:\n",
    "- Larger homes (square footage, number of rooms) are strongly correlated with higher prices.\n",
    "- Location-related variables (Neighborhood) also play a big role.\n",
    "- Among models, **Random Forest with tuned hyperparameters performed best** with the lowest RMSE and highest RÂ².\n",
    "- Linear models provide interpretability, while tree-based models capture complex non-linear relationships.\n",
    "\n",
    "### Recommendations:\n",
    "- Real estate professionals can use this model for better pricing.\n",
    "- Policymakers could identify affordability trends by analyzing influential features.\n",
    "- Next steps: try gradient boosting methods (XGBoost, LightGBM) for further performance gains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
